HF_TOKEN=your_hf_token_here
MODEL_ID=meta-llama/Llama-3.2-1B-Instruct
USE_HF_INFERENCE=true  # Switch between true/false to change behavior true means using HF inference , false means locally
